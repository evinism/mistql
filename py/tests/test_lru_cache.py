import time
import pytest
from mistql import MistQLInstance


# Mostly autogenerated


def test_lru_cache_basic_functionality():
    """Test that LRU caching works for repeated queries."""
    # Create instance with small cache size
    mq = MistQLInstance(parse_lru_cache_size=2)

    # Test data
    data = [{"name": "John", "age": 30}, {"name": "Jane", "age": 25}]

    # First query - should parse and cache
    result1 = mq.query("filter @.age > 26 @ | map name", data)
    assert result1 == ["John"]

    # Same query again - should use cache
    result2 = mq.query("filter @.age > 26 @ | map name", data)
    assert result2 == ["John"]

    # Different query - should parse and cache
    result3 = mq.query("count @", data)
    assert result3 == 2


def test_lru_cache_size_limit():
    """Test that cache respects size limits and evicts old entries."""
    # Create instance with cache size of 1
    mq = MistQLInstance(parse_lru_cache_size=1)

    data = [{"name": "John", "age": 30}, {"name": "Jane", "age": 25}]

    # First query - should be cached
    result1 = mq.query("filter @.age > 26 @", data)
    assert result1 == [{"name": "John", "age": 30}]

    # Second different query - should evict first query from cache
    result2 = mq.query("count @", data)
    assert result2 == 2

    # Third query (same as first) - should parse again since it was evicted
    result3 = mq.query("filter @.age > 26 @", data)
    assert result3 == [{"name": "John", "age": 30}]


def test_lru_cache_performance():
    """Test that cached queries are faster than uncached ones."""
    # Create instance with cache
    mq_cached = MistQLInstance(parse_lru_cache_size=10)

    # Create instance without cache (size 0 effectively disables caching)
    mq_uncached = MistQLInstance(parse_lru_cache_size=0)

    data = [
        {"name": "John", "age": 30},
        {"name": "Jane", "age": 25},
    ] * 10  # Larger dataset
    complex_query = "filter age > 26 @ | map name | filter @ != null | count"

    # Warm up the cached instance
    mq_cached.query(complex_query, data)

    # Time cached query
    start_time = time.time()
    for _ in range(10):
        mq_cached.query(complex_query, data)
    cached_time = time.time() - start_time

    # Time uncached query
    start_time = time.time()
    for _ in range(10):
        mq_uncached.query(complex_query, data)
    uncached_time = time.time() - start_time

    # Cached should be significantly faster
    # Note: This test might be flaky on very fast machines, but the ratio should be substantial
    assert cached_time < uncached_time, (
        f"Cached time: {cached_time}, Uncached time: {uncached_time}"
    )


def test_lru_cache_statistics():
    """Test that we can access cache statistics."""
    mq = MistQLInstance(parse_lru_cache_size=2)

    data = [{"name": "John", "age": 30}]

    # Check initial cache stats
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.hits == 0
    assert cache_info.misses == 0
    assert cache_info.maxsize == 2
    assert cache_info.currsize == 0

    # First query - should be a miss
    mq.query("count @", data)
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.misses == 1
    assert cache_info.hits == 0
    assert cache_info.currsize == 1

    # Same query again - should be a hit
    mq.query("count @", data)
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.misses == 1
    assert cache_info.hits == 1
    assert cache_info.currsize == 1

    # Different query - should be a miss
    mq.query("map @.name @", data)
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.misses == 2
    assert cache_info.hits == 1
    assert cache_info.currsize == 2


def test_lru_cache_clear():
    """Test that cache can be cleared."""
    mq = MistQLInstance(parse_lru_cache_size=2)

    data = [{"name": "John", "age": 30}]

    # Add some queries to cache
    mq.query("count @", data)
    mq.query("map name @", data)

    # Verify cache has entries
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.currsize == 2

    # Clear cache
    mq._cached_parse.cache_clear()

    # Verify cache is empty
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.currsize == 0
    assert cache_info.hits == 0
    assert cache_info.misses == 0


def test_lru_cache_different_instances():
    """Test that different instances have separate caches."""
    mq1 = MistQLInstance(parse_lru_cache_size=2)
    mq2 = MistQLInstance(parse_lru_cache_size=2)

    data = [{"name": "John", "age": 30}]

    # Add query to first instance
    mq1.query("count @", data)

    # Check that second instance doesn't have it cached
    cache_info1 = mq1._cached_parse.cache_info()
    cache_info2 = mq2._cached_parse.cache_info()

    assert cache_info1.currsize == 1
    assert cache_info2.currsize == 0


def test_lru_cache_edge_cases():
    """Test edge cases for LRU cache."""
    # Test with cache size 0 (should still work but not cache)
    mq = MistQLInstance(parse_lru_cache_size=0)
    data = [{"name": "John", "age": 30}]

    result1 = mq.query("count @", data)
    result2 = mq.query("count @", data)

    assert result1 == result2 == 1

    # Cache should be empty
    cache_info = mq._cached_parse.cache_info()
    assert cache_info.currsize == 0
    assert cache_info.maxsize == 0
